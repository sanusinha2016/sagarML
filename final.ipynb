{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Evaluating 5-Minute Model...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.5352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.35      0.42        34\n",
      "           1       0.54      0.70      0.61        37\n",
      "\n",
      "    accuracy                           0.54        71\n",
      "   macro avg       0.53      0.53      0.52        71\n",
      "weighted avg       0.53      0.54      0.52        71\n",
      "\n",
      "[[12 22]\n",
      " [11 26]]\n",
      "\n",
      "Training and Evaluating 1-Hour Model...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.6667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.80      0.67      0.62         6\n",
      "weighted avg       0.80      0.67      0.62         6\n",
      "\n",
      "[[1 2]\n",
      " [0 3]]\n",
      "\n",
      "Training and Evaluating 1-Week Model...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.7083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68        25\n",
      "           1       0.66      0.83      0.73        23\n",
      "\n",
      "    accuracy                           0.71        48\n",
      "   macro avg       0.72      0.71      0.71        48\n",
      "weighted avg       0.73      0.71      0.71        48\n",
      "\n",
      "[[15 10]\n",
      " [ 4 19]]\n",
      "\n",
      "Training and Evaluating 15-Days Model...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy: 0.8750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.82        18\n",
      "           1       0.88      0.93      0.90        30\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.88      0.86      0.86        48\n",
      "weighted avg       0.88      0.88      0.87        48\n",
      "\n",
      "[[14  4]\n",
      " [ 2 28]]\n",
      "\n",
      "Predictions for the next period:\n",
      "Next 5-Minute Prediction (1 = Up, 0 = Down): [1]\n",
      "Next 1-Hour Prediction (1 = Up, 0 = Down): [1]\n",
      "Next 1-Week Prediction (1 = Up, 0 = Down): [1]\n",
      "Next 15-Days Prediction (1 = Up, 0 = Down): [1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  \n",
    "\n",
    "ticker_symbol = 'AAPL'\n",
    "stock_data = yf.Ticker(ticker_symbol)\n",
    "\n",
    "df_5min = stock_data.history(period=\"5d\", interval=\"5m\")\n",
    "\n",
    "df_1hour = stock_data.history(period=\"5d\", interval=\"1h\")\n",
    "\n",
    "df_daily = stock_data.history(period='1y')\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    df['EMA_5'] = df['Close'].ewm(span=5, adjust=False).mean()\n",
    "    df['EMA_21'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
    "    df['Crossover'] = (df['EMA_5'] > df['EMA_21']) & (df['EMA_5'].shift(1) <= df['EMA_21'].shift(1))\n",
    "\n",
    "    df['Price_Change'] = df['Close'].diff()\n",
    "    df['Gain'] = df['Price_Change'].where(df['Price_Change'] > 0, 0)\n",
    "    df['Loss'] = -df['Price_Change'].where(df['Price_Change'] < 0, 0)\n",
    "\n",
    "    df['Avg_Gain'] = df['Gain'].rolling(window=14, min_periods=1).mean()\n",
    "    df['Avg_Loss'] = df['Loss'].rolling(window=14, min_periods=1).mean()\n",
    "\n",
    "    df['RS'] = df['Avg_Gain'] / df['Avg_Loss']\n",
    "    df['RSI'] = 100 - (100 / (1 + df['RS']))\n",
    "\n",
    "    df['RSI_Above_50'] = df['RSI'] >= 50\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.bfill(inplace=True) \n",
    "\n",
    "    return df\n",
    "\n",
    "df_5min = preprocess_data(df_5min)\n",
    "df_1hour = preprocess_data(df_1hour)\n",
    "df_daily = preprocess_data(df_daily)\n",
    "\n",
    "def create_targets(df, target_shift):\n",
    "    df['Next_Close'] = df['Close'].shift(-target_shift)\n",
    "    df['Price_Up'] = (df['Next_Close'] > df['Close']).astype(int)\n",
    "    df.dropna(inplace=True) \n",
    "    return df\n",
    "\n",
    "df_5min = create_targets(df_5min, target_shift=1)  \n",
    "df_1hour = create_targets(df_1hour, target_shift=1) \n",
    "\n",
    "df_daily['Next_Week_Close'] = df_daily['Close'].shift(-5) \n",
    "df_daily['Price_Up_1_Week'] = (df_daily['Next_Week_Close'] > df_daily['Close']).astype(int)\n",
    "\n",
    "df_daily['Next_15_Days_Close'] = df_daily['Close'].shift(-15) \n",
    "df_daily['Price_Up_15_Days'] = (df_daily['Next_15_Days_Close'] > df_daily['Close']).astype(int)\n",
    "\n",
    "df_daily.dropna(inplace=True)\n",
    "\n",
    "features = ['EMA_5', 'EMA_21', 'Crossover', 'RSI', 'RSI_Above_50', 'Price_Change', 'Gain', 'Loss', 'Avg_Gain', 'Avg_Loss', 'RS']\n",
    "\n",
    "X_5min = df_5min[features]\n",
    "X_1hour = df_1hour[features]\n",
    "X_daily = df_daily[features]\n",
    "\n",
    "y_1week = df_daily['Price_Up_1_Week']\n",
    "y_15days = df_daily['Price_Up_15_Days']\n",
    "\n",
    "y_5min = df_5min['Price_Up']\n",
    "y_1hour = df_1hour['Price_Up']\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_5min_imputed = imputer.fit_transform(X_5min)\n",
    "X_1hour_imputed = imputer.fit_transform(X_1hour)\n",
    "X_daily_imputed = imputer.fit_transform(X_daily)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_5min_scaled = scaler.fit_transform(X_5min_imputed)\n",
    "X_1hour_scaled = scaler.fit_transform(X_1hour_imputed)\n",
    "X_daily_scaled = scaler.fit_transform(X_daily_imputed)\n",
    "\n",
    "X_train_5min, X_test_5min, y_train_5min, y_test_5min = train_test_split(X_5min_scaled, y_5min, test_size=0.2, random_state=42)\n",
    "X_train_1hour, X_test_1hour, y_train_1hour, y_test_1hour = train_test_split(X_1hour_scaled, y_1hour, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_daily, X_test_daily, y_train_1week, y_test_1week = train_test_split(X_daily_scaled, y_1week, test_size=0.2, random_state=42)\n",
    "X_train_daily_15, X_test_daily_15, y_train_15days, y_test_15days = train_test_split(X_daily_scaled, y_15days, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "def train_rf_model(X_train, y_train, X_test, y_test):\n",
    "    grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    return best_model\n",
    "\n",
    "print(\"\\nTraining and Evaluating 5-Minute Model...\")\n",
    "best_model_5min = train_rf_model(X_train_5min, y_train_5min, X_test_5min, y_test_5min)\n",
    "\n",
    "print(\"\\nTraining and Evaluating 1-Hour Model...\")\n",
    "best_model_1hour = train_rf_model(X_train_1hour, y_train_1hour, X_test_1hour, y_test_1hour)\n",
    "\n",
    "print(\"\\nTraining and Evaluating 1-Week Model...\")\n",
    "best_model_1week = train_rf_model(X_train_daily, y_train_1week, X_test_daily, y_test_1week)\n",
    "\n",
    "print(\"\\nTraining and Evaluating 15-Days Model...\")\n",
    "best_model_15days = train_rf_model(X_train_daily_15, y_train_15days, X_test_daily_15, y_test_15days)\n",
    "\n",
    "def predict_next(model, X_scaled):\n",
    "    last_data = X_scaled[-1:].reshape(1, -1)\n",
    "    prediction = model.predict(last_data)\n",
    "    return prediction\n",
    "\n",
    "print(\"\\nPredictions for the next period:\")\n",
    "print(f\"Next 5-Minute Prediction (1 = Up, 0 = Down): {predict_next(best_model_5min, X_5min_scaled)}\")\n",
    "print(f\"Next 1-Hour Prediction (1 = Up, 0 = Down): {predict_next(best_model_1hour, X_1hour_scaled)}\")\n",
    "print(f\"Next 1-Week Prediction (1 = Up, 0 = Down): {predict_next(best_model_1week, X_daily_scaled)}\")\n",
    "print(f\"Next 15-Days Prediction (1 = Up, 0 = Down): {predict_next(best_model_15days, X_daily_scaled)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_15days.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save trained models\n",
    "joblib.dump(best_model_5min, 'model_5min.pkl')\n",
    "joblib.dump(best_model_1hour, 'model_1hour.pkl')\n",
    "joblib.dump(best_model_1week, 'model_1week.pkl')\n",
    "joblib.dump(best_model_15days, 'model_15days.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Model for GOOGL has been trained and saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Function to get stock data\n",
    "def get_stock_data(ticker):\n",
    "    stock_data = yf.Ticker(ticker)\n",
    "    df_5min = stock_data.history(period=\"5d\", interval=\"5m\")\n",
    "    df_1hour = stock_data.history(period=\"5d\", interval=\"1h\")\n",
    "    df_daily = stock_data.history(period='1y')\n",
    "    return df_5min, df_1hour, df_daily\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(df):\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    df['EMA_5'] = df['Close'].ewm(span=5, adjust=False).mean()\n",
    "    df['EMA_21'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
    "    df['Crossover'] = (df['EMA_5'] > df['EMA_21']) & (df['EMA_5'].shift(1) <= df['EMA_21'].shift(1))\n",
    "\n",
    "    df['Price_Change'] = df['Close'].diff()\n",
    "    df['Gain'] = df['Price_Change'].where(df['Price_Change'] > 0, 0)\n",
    "    df['Loss'] = -df['Price_Change'].where(df['Price_Change'] < 0, 0)\n",
    "\n",
    "    df['Avg_Gain'] = df['Gain'].rolling(window=14, min_periods=1).mean()\n",
    "    df['Avg_Loss'] = df['Loss'].rolling(window=14, min_periods=1).mean()\n",
    "\n",
    "    df['RS'] = df['Avg_Gain'] / df['Avg_Loss']\n",
    "    df['RSI'] = 100 - (100 / (1 + df['RS']))\n",
    "\n",
    "    df['RSI_Above_50'] = df['RSI'] >= 50\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.bfill(inplace=True) \n",
    "\n",
    "    return df\n",
    "\n",
    "# Creating Targets\n",
    "def create_targets(df, target_shift):\n",
    "    df['Next_Close'] = df['Close'].shift(-target_shift)\n",
    "    df['Price_Up'] = (df['Next_Close'] > df['Close']).astype(int)\n",
    "    df.dropna(inplace=True) \n",
    "    return df\n",
    "\n",
    "# Model training function\n",
    "def train_rf_model(X_train, y_train):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Function to prepare data, train the model, and save it\n",
    "def prepare_and_train_model(ticker):\n",
    "    # Get stock data\n",
    "    df_5min, df_1hour, df_daily = get_stock_data(ticker)\n",
    "\n",
    "    # Preprocess data\n",
    "    df_5min = preprocess_data(df_5min)\n",
    "    df_1hour = preprocess_data(df_1hour)\n",
    "    df_daily = preprocess_data(df_daily)\n",
    "\n",
    "    # Create targets\n",
    "    df_5min = create_targets(df_5min, target_shift=1)\n",
    "    df_1hour = create_targets(df_1hour, target_shift=1)\n",
    "    df_daily['Next_Week_Close'] = df_daily['Close'].shift(-5) \n",
    "    df_daily['Price_Up_1_Week'] = (df_daily['Next_Week_Close'] > df_daily['Close']).astype(int)\n",
    "    df_daily.dropna(inplace=True)\n",
    "\n",
    "    # Features for the model\n",
    "    features = ['EMA_5', 'EMA_21', 'Crossover', 'RSI', 'RSI_Above_50', 'Price_Change', 'Gain', 'Loss', 'Avg_Gain', 'Avg_Loss', 'RS']\n",
    "\n",
    "    X_5min = df_5min[features]\n",
    "    y_5min = df_5min['Price_Up']\n",
    "    \n",
    "    # Imputer and Scaler for handling missing data and scaling\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_5min_imputed = imputer.fit_transform(X_5min)\n",
    "    X_5min_scaled = scaler.fit_transform(X_5min_imputed)\n",
    "    \n",
    "    # Train-Test Split\n",
    "    X_train_5min, X_test_5min, y_train_5min, y_test_5min = train_test_split(X_5min_scaled, y_5min, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model = train_rf_model(X_train_5min, y_train_5min)\n",
    "    \n",
    "    # Save the model using joblib\n",
    "    joblib.dump(model, f'{ticker}_5min_model.pkl')\n",
    "    joblib.dump(imputer, f'{ticker}_imputer.pkl')\n",
    "    joblib.dump(scaler, f'{ticker}_scaler.pkl')\n",
    "\n",
    "    return model, imputer, scaler\n",
    "\n",
    "# Specify the stock ticker (for example AAPL)\n",
    "ticker = 'GOOGL'  # Change this as needed\n",
    "\n",
    "# Train the model and save it\n",
    "model, imputer, scaler = prepare_and_train_model(ticker)\n",
    "\n",
    "print(f\"Model for {ticker} has been trained and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and Saving 5-Minute Model...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Model saved as AAPL_5min_rf_model.pkl\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 0.5352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.35      0.42        34\n",
      "           1       0.54      0.70      0.61        37\n",
      "\n",
      "    accuracy                           0.54        71\n",
      "   macro avg       0.53      0.53      0.52        71\n",
      "weighted avg       0.53      0.54      0.52        71\n",
      "\n",
      "[[12 22]\n",
      " [11 26]]\n",
      "\n",
      "Training and Saving 1-Hour Model...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Model saved as AAPL_1hour_rf_model.pkl\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy: 0.6667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50         3\n",
      "           1       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.80      0.67      0.62         6\n",
      "weighted avg       0.80      0.67      0.62         6\n",
      "\n",
      "[[1 2]\n",
      " [0 3]]\n",
      "\n",
      "Training and Saving 1-Week Model...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Model saved as AAPL_1week_rf_model.pkl\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy: 0.7083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68        25\n",
      "           1       0.66      0.83      0.73        23\n",
      "\n",
      "    accuracy                           0.71        48\n",
      "   macro avg       0.72      0.71      0.71        48\n",
      "weighted avg       0.73      0.71      0.71        48\n",
      "\n",
      "[[15 10]\n",
      " [ 4 19]]\n",
      "\n",
      "Training and Saving 15-Days Model...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Model saved as AAPL_15days_rf_model.pkl\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Accuracy: 0.8750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.82        18\n",
      "           1       0.88      0.93      0.90        30\n",
      "\n",
      "    accuracy                           0.88        48\n",
      "   macro avg       0.88      0.86      0.86        48\n",
      "weighted avg       0.88      0.88      0.87        48\n",
      "\n",
      "[[14  4]\n",
      " [ 2 28]]\n",
      "\n",
      "Predictions for the next period:\n",
      "Next 5-Minute Prediction (1 = Up, 0 = Down): [1]\n",
      "Next 1-Hour Prediction (1 = Up, 0 = Down): [1]\n",
      "Next 1-Week Prediction (1 = Up, 0 = Down): [1]\n",
      "Next 15-Days Prediction (1 = Up, 0 = Down): [1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib  # Import joblib for saving and loading models\n",
    "\n",
    "# Function to fetch stock data and process it\n",
    "def fetch_stock_data(ticker_symbol):\n",
    "    stock_data = yf.Ticker(ticker_symbol)\n",
    "    \n",
    "    # Downloading stock data with different time intervals\n",
    "    df_5min = stock_data.history(period=\"5d\", interval=\"5m\")\n",
    "    df_1hour = stock_data.history(period=\"5d\", interval=\"1h\")\n",
    "    df_daily = stock_data.history(period='1y')\n",
    "    \n",
    "    return df_5min, df_1hour, df_daily\n",
    "\n",
    "# Data preprocessing function\n",
    "def preprocess_data(df):\n",
    "    df.index = pd.to_datetime(df.index).tz_localize(None)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    df['EMA_5'] = df['Close'].ewm(span=5, adjust=False).mean()\n",
    "    df['EMA_21'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
    "    df['Crossover'] = (df['EMA_5'] > df['EMA_21']) & (df['EMA_5'].shift(1) <= df['EMA_21'].shift(1))\n",
    "\n",
    "    df['Price_Change'] = df['Close'].diff()\n",
    "    df['Gain'] = df['Price_Change'].where(df['Price_Change'] > 0, 0)\n",
    "    df['Loss'] = -df['Price_Change'].where(df['Price_Change'] < 0, 0)\n",
    "\n",
    "    df['Avg_Gain'] = df['Gain'].rolling(window=14, min_periods=1).mean()\n",
    "    df['Avg_Loss'] = df['Loss'].rolling(window=14, min_periods=1).mean()\n",
    "\n",
    "    df['RS'] = df['Avg_Gain'] / df['Avg_Loss']\n",
    "    df['RSI'] = 100 - (100 / (1 + df['RS']))\n",
    "\n",
    "    df['RSI_Above_50'] = df['RSI'] >= 50\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.bfill(inplace=True) \n",
    "\n",
    "    return df\n",
    "\n",
    "# Target creation for prediction\n",
    "def create_targets(df, target_shift):\n",
    "    df['Next_Close'] = df['Close'].shift(-target_shift)\n",
    "    df['Price_Up'] = (df['Next_Close'] > df['Close']).astype(int)\n",
    "    df.dropna(inplace=True) \n",
    "    return df\n",
    "\n",
    "# Function to train Random Forest model\n",
    "def train_rf_model(X_train, y_train, X_test, y_test, model_name):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Saving the model using joblib\n",
    "    joblib.dump(best_model, f'{model_name}_rf_model.pkl')\n",
    "    print(f\"Model saved as {model_name}_rf_model.pkl\")\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "# Function to load a saved model\n",
    "def load_model(model_name):\n",
    "    model = joblib.load(f'{model_name}_rf_model.pkl')\n",
    "    print(f\"Model loaded from {model_name}_rf_model.pkl\")\n",
    "    return model\n",
    "\n",
    "# Function to make predictions\n",
    "def predict_next(model, X_scaled):\n",
    "    last_data = X_scaled[-1:].reshape(1, -1)\n",
    "    prediction = model.predict(last_data)\n",
    "    return prediction\n",
    "\n",
    "# Main function to execute the workflow\n",
    "def main(ticker_symbol):\n",
    "    # Fetch stock data\n",
    "    df_5min, df_1hour, df_daily = fetch_stock_data(ticker_symbol)\n",
    "    \n",
    "    # Preprocess data\n",
    "    df_5min = preprocess_data(df_5min)\n",
    "    df_1hour = preprocess_data(df_1hour)\n",
    "    df_daily = preprocess_data(df_daily)\n",
    "\n",
    "    # Create targets\n",
    "    df_5min = create_targets(df_5min, target_shift=1)  \n",
    "    df_1hour = create_targets(df_1hour, target_shift=1) \n",
    "    df_daily['Next_Week_Close'] = df_daily['Close'].shift(-5) \n",
    "    df_daily['Price_Up_1_Week'] = (df_daily['Next_Week_Close'] > df_daily['Close']).astype(int)\n",
    "\n",
    "    df_daily['Next_15_Days_Close'] = df_daily['Close'].shift(-15) \n",
    "    df_daily['Price_Up_15_Days'] = (df_daily['Next_15_Days_Close'] > df_daily['Close']).astype(int)\n",
    "    df_daily.dropna(inplace=True)\n",
    "\n",
    "    # Define features\n",
    "    features = ['EMA_5', 'EMA_21', 'Crossover', 'RSI', 'RSI_Above_50', 'Price_Change', 'Gain', 'Loss', 'Avg_Gain', 'Avg_Loss', 'RS']\n",
    "\n",
    "    # Split data into features and targets\n",
    "    X_5min = df_5min[features]\n",
    "    X_1hour = df_1hour[features]\n",
    "    X_daily = df_daily[features]\n",
    "\n",
    "    y_5min = df_5min['Price_Up']\n",
    "    y_1hour = df_1hour['Price_Up']\n",
    "    y_1week = df_daily['Price_Up_1_Week']\n",
    "    y_15days = df_daily['Price_Up_15_Days']\n",
    "\n",
    "    # Impute and scale the data\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    X_5min_scaled = scaler.fit_transform(imputer.fit_transform(X_5min))\n",
    "    X_1hour_scaled = scaler.fit_transform(imputer.fit_transform(X_1hour))\n",
    "    X_daily_scaled = scaler.fit_transform(imputer.fit_transform(X_daily))\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train_5min, X_test_5min, y_train_5min, y_test_5min = train_test_split(X_5min_scaled, y_5min, test_size=0.2, random_state=42)\n",
    "    X_train_1hour, X_test_1hour, y_train_1hour, y_test_1hour = train_test_split(X_1hour_scaled, y_1hour, test_size=0.2, random_state=42)\n",
    "    X_train_daily, X_test_daily, y_train_1week, y_test_1week = train_test_split(X_daily_scaled, y_1week, test_size=0.2, random_state=42)\n",
    "    X_train_daily_15, X_test_daily_15, y_train_15days, y_test_15days = train_test_split(X_daily_scaled, y_15days, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train and save models for different time intervals\n",
    "    print(\"\\nTraining and Saving 5-Minute Model...\")\n",
    "    best_model_5min = train_rf_model(X_train_5min, y_train_5min, X_test_5min, y_test_5min, f'{ticker_symbol}_5min')\n",
    "\n",
    "    print(\"\\nTraining and Saving 1-Hour Model...\")\n",
    "    best_model_1hour = train_rf_model(X_train_1hour, y_train_1hour, X_test_1hour, y_test_1hour, f'{ticker_symbol}_1hour')\n",
    "\n",
    "    print(\"\\nTraining and Saving 1-Week Model...\")\n",
    "    best_model_1week = train_rf_model(X_train_daily, y_train_1week, X_test_daily, y_test_1week, f'{ticker_symbol}_1week')\n",
    "\n",
    "    print(\"\\nTraining and Saving 15-Days Model...\")\n",
    "    best_model_15days = train_rf_model(X_train_daily_15, y_train_15days, X_test_daily_15, y_test_15days, f'{ticker_symbol}_15days')\n",
    "\n",
    "    # Example predictions\n",
    "    print(\"\\nPredictions for the next period:\")\n",
    "    print(f\"Next 5-Minute Prediction (1 = Up, 0 = Down): {predict_next(best_model_5min, X_5min_scaled)}\")\n",
    "    print(f\"Next 1-Hour Prediction (1 = Up, 0 = Down): {predict_next(best_model_1hour, X_1hour_scaled)}\")\n",
    "    print(f\"Next 1-Week Prediction (1 = Up, 0 = Down): {predict_next(best_model_1week, X_daily_scaled)}\")\n",
    "    print(f\"Next 15-Days Prediction (1 = Up, 0 = Down): {predict_next(best_model_15days, X_daily_scaled)}\")\n",
    "\n",
    "# Run the model for a given stock ticker (can change 'AAPL' to any stock symbol)\n",
    "ticker_symbol = 'AAPL'\n",
    "main(ticker_symbol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
